{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/research/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"nuprl/EditPackFT\", split=\"train\")\n",
    "ds = ds.select(range(5000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "def proc_row(row):\n",
    "    row[\"patch\"] = \"\\n\".join(difflib.unified_diff(row[\"old_contents\"].splitlines(), row[\"new_contents\"].splitlines(), n=3))\n",
    "    if os.path.exists(f\"./cache/{row['commit']}.txt\"):\n",
    "        f = open(f\"./cache/{row['commit']}.txt\", \"r\")\n",
    "        row[\"inst\"] = f.read()\n",
    "        f.close()\n",
    "        return row\n",
    "    \n",
    "    # Write the commit\n",
    "    prompt = f\"\"\"Given the following file, the corresponding patch made, and the commit message, write a detailed instruction given to a developer in order to produce the patch.\n",
    "# File:\n",
    "{row['old_contents']}\n",
    "\n",
    "# Commit message:\n",
    "{row['message']}\n",
    "\n",
    "# Patch:\n",
    "{row['patch']}\n",
    "\n",
    "# Describe the changes made in the code in a concise format (two sentences), formatted as an instruction (imperative tense) to an intelligent and independent software developer. Don't mention line numbers or write out long chunks of code (more than 3 lines). Include 1-2 line chunks of code in your instruction if required.\"\"\"\n",
    "    \n",
    "    detailed_inst = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    f = open(f\"./cache/{row['commit']}.txt\", \"w+\")\n",
    "    f.write(detailed_inst)\n",
    "    f.close()\n",
    "\n",
    "    row[\"inst\"] = detailed_inst \n",
    "    return row\n",
    "\n",
    "if not(os.path.exists(\"./cache\")):\n",
    "    os.mkdir(\"./cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- \n",
      "\n",
      "+++ \n",
      "\n",
      "@@ -9,6 +9,9 @@\n",
      "\n",
      " class Broker(object):\n",
      "     def __init__(self, config):\n",
      "         self.connection = BrokerConnection(**config)\n",
      "+        with producers[self.connection].acquire(block=False) as producer:\n",
      "+            for queue in task_queues:\n",
      "+                maybe_declare(queue, producer.channel)\n",
      " \n",
      "     def delay(self, func, *args, **kwargs):\n",
      "         payload = {\n",
      "@@ -18,8 +21,6 @@\n",
      "\n",
      "         }\n",
      " \n",
      "         with producers[self.connection].acquire(block=False) as producer:\n",
      "-            for queue in task_queues:\n",
      "-                maybe_declare(queue, producer.channel)\n",
      "             producer.publish(payload,\n",
      "                 exchange=task_exchange,\n",
      "                 serializer=\"pickle\",\n",
      "1. Adjust the `__init__` method in the `Broker` class to include a loop that declares queues using `maybe_declare`.\n",
      "2. Move the existing loop that declares queues in the `delay` method above the `producer.publish` call.\n"
     ]
    }
   ],
   "source": [
    "new_row = proc_row(ds[0])\n",
    "print(new_row[\"patch\"])\n",
    "print(new_row[\"inst\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=10): 100%|██████████| 5000/5000 [04:46<00:00, 17.46 examples/s]   \n",
      "/opt/anaconda3/envs/research/lib/python3.12/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(proc_row, num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 32.93ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:12<00:00, 12.35s/it]\n"
     ]
    }
   ],
   "source": [
    "ds.push_to_hub(\"vdaita/editpackft_inst\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
