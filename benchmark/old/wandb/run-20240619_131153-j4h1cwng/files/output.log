/home/vijay/.local/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 4.3848, 'grad_norm': 3.008498191833496, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.00044662795891022776}
{'loss': 4.1329, 'grad_norm': 2.618403911590576, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0008932559178204555}
{'loss': 1.9652, 'grad_norm': 0.700329601764679, 'learning_rate': 3e-06, 'epoch': 0.0013398838767306833}
{'loss': 4.3087, 'grad_norm': 2.668053388595581, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.001786511835640911}
{'loss': 2.2255, 'grad_norm': 0.7106661200523376, 'learning_rate': 5e-06, 'epoch': 0.0022331397945511387}
{'loss': 3.4725, 'grad_norm': 86.9999771118164, 'learning_rate': 6e-06, 'epoch': 0.0026797677534613666}
{'loss': 4.9182, 'grad_norm': 3.213226795196533, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0031263957123715946}
{'loss': 3.1951, 'grad_norm': 1.9032158851623535, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.003573023671281822}
{'loss': 2.002, 'grad_norm': 0.8487870097160339, 'learning_rate': 9e-06, 'epoch': 0.00401965163019205}
{'loss': 2.2905, 'grad_norm': 0.8179285526275635, 'learning_rate': 1e-05, 'epoch': 0.0044662795891022775}
{'loss': 1.871, 'grad_norm': 0.7717688083648682, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.004912907548012505}
{'loss': 3.9502, 'grad_norm': 3.4857664108276367, 'learning_rate': 1.2e-05, 'epoch': 0.005359535506922733}
{'loss': 2.1671, 'grad_norm': 0.9320575594902039, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.005806163465832961}
{'loss': 3.8835, 'grad_norm': 2.344250202178955, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.006252791424743189}
{'loss': 1.9472, 'grad_norm': 0.7859559655189514, 'learning_rate': 1.5e-05, 'epoch': 0.006699419383653417}
{'loss': 1.8514, 'grad_norm': 0.7515720725059509, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.007146047342563644}
{'loss': 2.1321, 'grad_norm': 0.9245752096176147, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.007592675301473872}
{'loss': 1.9138, 'grad_norm': 0.821535587310791, 'learning_rate': 1.8e-05, 'epoch': 0.0080393032603841}
{'loss': 1.9534, 'grad_norm': 0.780159592628479, 'learning_rate': 1.9e-05, 'epoch': 0.008485931219294328}
{'loss': 4.1883, 'grad_norm': 2.6777799129486084, 'learning_rate': 2e-05, 'epoch': 0.008932559178204555}
{'loss': 1.9277, 'grad_norm': 0.7659704089164734, 'learning_rate': 2.1e-05, 'epoch': 0.009379187137114784}
{'loss': 1.9197, 'grad_norm': 0.8448395729064941, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.00982581509602501}
{'loss': 1.7137, 'grad_norm': 0.9284173846244812, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.01027244305493524}
{'loss': 2.743, 'grad_norm': 1.4774709939956665, 'learning_rate': 2.4e-05, 'epoch': 0.010719071013845467}
{'loss': 1.9339, 'grad_norm': 0.8134607672691345, 'learning_rate': 2.5e-05, 'epoch': 0.011165698972755694}
{'loss': 1.8477, 'grad_norm': 0.7912702560424805, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.011612326931665922}
{'loss': 4.2045, 'grad_norm': 3.3526177406311035, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.01205895489057615}
{'loss': 4.9977, 'grad_norm': 3.885894775390625, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.012505582849486378}
{'loss': 1.8665, 'grad_norm': 0.8518345355987549, 'learning_rate': 2.9e-05, 'epoch': 0.012952210808396605}
{'loss': 4.2159, 'grad_norm': 4.817198276519775, 'learning_rate': 3e-05, 'epoch': 0.013398838767306834}
{'loss': 1.8418, 'grad_norm': 0.8360645174980164, 'learning_rate': 3.1e-05, 'epoch': 0.013845466726217061}
Traceback (most recent call last):
  File "/home/vijay/diff-model/train_sft.py", line 218, in <module>
    main(args)
  File "/home/vijay/diff-model/train_sft.py", line 206, in main
    run_training(args, train_dataset, eval_dataset)
  File "/home/vijay/diff-model/train_sft.py", line 197, in run_training
    trainer.train()
  File "/home/vijay/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 440, in train
    output = super().train(*args, **kwargs)
  File "/home/vijay/.local/lib/python3.10/site-packages/transformers/trainer.py", line 1885, in train
    return inner_training_loop(
  File "/home/vijay/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2216, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/vijay/.local/lib/python3.10/site-packages/transformers/trainer.py", line 3241, in training_step
    torch.cuda.empty_cache()
  File "/home/vijay/.local/lib/python3.10/site-packages/torch/cuda/memory.py", line 162, in empty_cache
    torch._C._cuda_emptyCache()
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home/vijay/diff-model/train_sft.py", line 218, in <module>
[rank0]:     main(args)
[rank0]:   File "/home/vijay/diff-model/train_sft.py", line 206, in main
[rank0]:     run_training(args, train_dataset, eval_dataset)
[rank0]:   File "/home/vijay/diff-model/train_sft.py", line 197, in run_training
[rank0]:     trainer.train()
[rank0]:   File "/home/vijay/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py", line 440, in train
[rank0]:     output = super().train(*args, **kwargs)
[rank0]:   File "/home/vijay/.local/lib/python3.10/site-packages/transformers/trainer.py", line 1885, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/home/vijay/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2216, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs)
[rank0]:   File "/home/vijay/.local/lib/python3.10/site-packages/transformers/trainer.py", line 3241, in training_step
[rank0]:     torch.cuda.empty_cache()
[rank0]:   File "/home/vijay/.local/lib/python3.10/site-packages/torch/cuda/memory.py", line 162, in empty_cache
[rank0]:     torch._C._cuda_emptyCache()
[rank0]: KeyboardInterrupt