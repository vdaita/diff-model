/home/vijay/.local/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.2889, 'grad_norm': 0.3178647458553314, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.00044662795891022776}
{'loss': 1.5143, 'grad_norm': 0.26586464047431946, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0008932559178204555}
{'loss': 1.2958, 'grad_norm': 0.655897319316864, 'learning_rate': 3e-06, 'epoch': 0.0013398838767306833}
{'loss': 1.5873, 'grad_norm': 0.3359854817390442, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.001786511835640911}
{'loss': 1.6042, 'grad_norm': 0.28149449825286865, 'learning_rate': 5e-06, 'epoch': 0.0022331397945511387}
{'loss': 1.3125, 'grad_norm': 0.35635682940483093, 'learning_rate': 6e-06, 'epoch': 0.0026797677534613666}
{'loss': 1.3487, 'grad_norm': 0.25092336535453796, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0031263957123715946}
{'loss': 1.1937, 'grad_norm': 0.22137288749217987, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.003573023671281822}
{'loss': 1.3402, 'grad_norm': 0.26497596502304077, 'learning_rate': 9e-06, 'epoch': 0.00401965163019205}
{'loss': 1.4243, 'grad_norm': 0.26526764035224915, 'learning_rate': 1e-05, 'epoch': 0.0044662795891022775}
{'loss': 1.2544, 'grad_norm': 0.2859072983264923, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.004912907548012505}
{'loss': 1.1983, 'grad_norm': 0.3533954322338104, 'learning_rate': 1.2e-05, 'epoch': 0.005359535506922733}
{'loss': 1.3677, 'grad_norm': 0.26700305938720703, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.005806163465832961}
{'loss': 1.3249, 'grad_norm': 0.3348095118999481, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.006252791424743189}
{'loss': 1.3663, 'grad_norm': 0.34744372963905334, 'learning_rate': 1.5e-05, 'epoch': 0.006699419383653417}
{'loss': 1.2255, 'grad_norm': 0.2572905719280243, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.007146047342563644}
{'loss': 1.3401, 'grad_norm': 0.3015117645263672, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.007592675301473872}
{'loss': 1.282, 'grad_norm': 0.28985652327537537, 'learning_rate': 1.8e-05, 'epoch': 0.0080393032603841}
{'loss': 1.3194, 'grad_norm': 0.3354719281196594, 'learning_rate': 1.9e-05, 'epoch': 0.008485931219294328}
{'loss': 1.4481, 'grad_norm': 0.28908902406692505, 'learning_rate': 2e-05, 'epoch': 0.008932559178204555}
{'loss': 1.2738, 'grad_norm': 0.3380753993988037, 'learning_rate': 2.1e-05, 'epoch': 0.009379187137114784}
{'loss': 1.3322, 'grad_norm': 0.335400253534317, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.00982581509602501}
{'loss': 1.1053, 'grad_norm': 0.3663159906864166, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.01027244305493524}
{'loss': 1.3453, 'grad_norm': 0.34794217348098755, 'learning_rate': 2.4e-05, 'epoch': 0.010719071013845467}
{'loss': 1.2846, 'grad_norm': 0.3157317042350769, 'learning_rate': 2.5e-05, 'epoch': 0.011165698972755694}
{'loss': 1.2545, 'grad_norm': 0.37462806701660156, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.011612326931665922}
{'loss': 1.4137, 'grad_norm': 0.7655346989631653, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.01205895489057615}
{'loss': 1.5479, 'grad_norm': 0.37414324283599854, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.012505582849486378}
{'loss': 1.241, 'grad_norm': 0.3235282301902771, 'learning_rate': 2.9e-05, 'epoch': 0.012952210808396605}
{'loss': 1.1947, 'grad_norm': 0.48222848773002625, 'learning_rate': 3e-05, 'epoch': 0.013398838767306834}
{'loss': 1.2726, 'grad_norm': 0.40194445848464966, 'learning_rate': 3.1e-05, 'epoch': 0.013845466726217061}
{'loss': 1.3704, 'grad_norm': 0.41512343287467957, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.014292094685127288}
{'loss': 1.2804, 'grad_norm': 0.4936971664428711, 'learning_rate': 3.3e-05, 'epoch': 0.014738722644037517}
{'loss': 1.1761, 'grad_norm': 0.6578119397163391, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.015185350602947744}
{'loss': 1.2772, 'grad_norm': 0.4029540717601776, 'learning_rate': 3.5e-05, 'epoch': 0.01563197856185797}
{'loss': 1.1567, 'grad_norm': 0.39405450224876404, 'learning_rate': 3.6e-05, 'epoch': 0.0160786065207682}
{'loss': 1.171, 'grad_norm': 0.5430426001548767, 'learning_rate': 3.7e-05, 'epoch': 0.01652523447967843}
{'loss': 1.1665, 'grad_norm': 0.5418576002120972, 'learning_rate': 3.8e-05, 'epoch': 0.016971862438588656}
{'loss': 1.2432, 'grad_norm': 0.5211575627326965, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.017418490397498883}
{'loss': 1.1585, 'grad_norm': 0.4523654878139496, 'learning_rate': 4e-05, 'epoch': 0.01786511835640911}
{'loss': 1.1542, 'grad_norm': 0.48872485756874084, 'learning_rate': 4.1e-05, 'epoch': 0.01831174631531934}
{'loss': 1.2012, 'grad_norm': 0.5572357773780823, 'learning_rate': 4.2e-05, 'epoch': 0.018758374274229567}
{'loss': 1.1196, 'grad_norm': 0.5070449709892273, 'learning_rate': 4.3e-05, 'epoch': 0.019205002233139794}
{'loss': 1.3146, 'grad_norm': 1.0941389799118042, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01965163019205002}
{'loss': 1.3449, 'grad_norm': 0.9343240261077881, 'learning_rate': 4.5e-05, 'epoch': 0.02009825815096025}
{'loss': 1.1, 'grad_norm': 0.5121154189109802, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.02054488610987048}
{'loss': 1.1917, 'grad_norm': 0.5340483784675598, 'learning_rate': 4.7e-05, 'epoch': 0.020991514068780706}
{'loss': 1.1338, 'grad_norm': 0.5634527206420898, 'learning_rate': 4.8e-05, 'epoch': 0.021438142027690933}
{'loss': 1.2745, 'grad_norm': 0.522468090057373, 'learning_rate': 4.9e-05, 'epoch': 0.02188476998660116}
{'loss': 1.0474, 'grad_norm': 0.8472476601600647, 'learning_rate': 5e-05, 'epoch': 0.022331397945511387}
{'loss': 1.0621, 'grad_norm': 0.5818490982055664, 'learning_rate': 5.1000000000000006e-05, 'epoch': 0.022778025904421618}
{'loss': 1.1328, 'grad_norm': 0.6115109920501709, 'learning_rate': 5.2000000000000004e-05, 'epoch': 0.023224653863331845}
{'loss': 0.9598, 'grad_norm': 0.7018309235572815, 'learning_rate': 5.300000000000001e-05, 'epoch': 0.023671281822242072}
{'loss': 1.0347, 'grad_norm': 0.601548969745636, 'learning_rate': 5.4000000000000005e-05, 'epoch': 0.0241179097811523}
{'loss': 1.1169, 'grad_norm': 0.6223593354225159, 'learning_rate': 5.500000000000001e-05, 'epoch': 0.02456453774006253}
{'loss': 1.1641, 'grad_norm': 0.56247878074646, 'learning_rate': 5.6000000000000006e-05, 'epoch': 0.025011165698972757}
{'loss': 1.1175, 'grad_norm': 0.5494381189346313, 'learning_rate': 5.6999999999999996e-05, 'epoch': 0.025457793657882984}
{'loss': 1.0051, 'grad_norm': 0.5626972913742065, 'learning_rate': 5.8e-05, 'epoch': 0.02590442161679321}
{'loss': 1.1592, 'grad_norm': 0.649382472038269, 'learning_rate': 5.9e-05, 'epoch': 0.026351049575703438}
{'loss': 1.1198, 'grad_norm': 0.60071861743927, 'learning_rate': 6e-05, 'epoch': 0.026797677534613668}
{'loss': 0.9566, 'grad_norm': 0.6898989677429199, 'learning_rate': 6.1e-05, 'epoch': 0.027244305493523895}
{'loss': 1.2595, 'grad_norm': 8.888854026794434, 'learning_rate': 6.2e-05, 'epoch': 0.027690933452434122}
{'loss': 1.1885, 'grad_norm': 0.6814509630203247, 'learning_rate': 6.3e-05, 'epoch': 0.02813756141134435}
{'loss': 1.2258, 'grad_norm': 0.788910448551178, 'learning_rate': 6.400000000000001e-05, 'epoch': 0.028584189370254576}
{'loss': 1.0473, 'grad_norm': 0.6559627056121826, 'learning_rate': 6.500000000000001e-05, 'epoch': 0.029030817329164807}
{'loss': 1.0118, 'grad_norm': 0.661052942276001, 'learning_rate': 6.6e-05, 'epoch': 0.029477445288075034}
{'loss': 1.0415, 'grad_norm': 0.7084713578224182, 'learning_rate': 6.7e-05, 'epoch': 0.02992407324698526}
{'loss': 1.0365, 'grad_norm': 0.6771821975708008, 'learning_rate': 6.800000000000001e-05, 'epoch': 0.030370701205895488}
{'loss': 1.0662, 'grad_norm': 0.6376591920852661, 'learning_rate': 6.9e-05, 'epoch': 0.030817329164805715}
{'loss': 0.819, 'grad_norm': 0.5198233723640442, 'learning_rate': 7e-05, 'epoch': 0.03126395712371594}
{'loss': 1.0332, 'grad_norm': 0.6308093070983887, 'learning_rate': 7.1e-05, 'epoch': 0.03171058508262617}
{'loss': 0.9491, 'grad_norm': 0.5957731008529663, 'learning_rate': 7.2e-05, 'epoch': 0.0321572130415364}
{'loss': 1.1137, 'grad_norm': 0.6673105359077454, 'learning_rate': 7.3e-05, 'epoch': 0.03260384100044663}
{'loss': 1.2851, 'grad_norm': 11.432857513427734, 'learning_rate': 7.4e-05, 'epoch': 0.03305046895935686}
{'loss': 1.0676, 'grad_norm': 0.7137519717216492, 'learning_rate': 7.500000000000001e-05, 'epoch': 0.033497096918267084}
{'loss': 1.1283, 'grad_norm': 0.973555862903595, 'learning_rate': 7.6e-05, 'epoch': 0.03394372487717731}
{'loss': 1.0211, 'grad_norm': 0.6179175972938538, 'learning_rate': 7.7e-05, 'epoch': 0.03439035283608754}
{'loss': 0.8945, 'grad_norm': 1.1787468194961548, 'learning_rate': 7.800000000000001e-05, 'epoch': 0.034836980794997766}
{'loss': 1.0398, 'grad_norm': 0.6885943412780762, 'learning_rate': 7.900000000000001e-05, 'epoch': 0.03528360875390799}
{'loss': 0.9449, 'grad_norm': 0.6513553857803345, 'learning_rate': 8e-05, 'epoch': 0.03573023671281822}
{'loss': 0.7902, 'grad_norm': 0.5357436537742615, 'learning_rate': 8.1e-05, 'epoch': 0.036176864671728454}
{'loss': 1.1448, 'grad_norm': 0.7709628343582153, 'learning_rate': 8.2e-05, 'epoch': 0.03662349263063868}
{'loss': 1.1895, 'grad_norm': 0.7874568104743958, 'learning_rate': 8.3e-05, 'epoch': 0.03707012058954891}
{'loss': 1.0082, 'grad_norm': 0.7005911469459534, 'learning_rate': 8.4e-05, 'epoch': 0.037516748548459135}
{'loss': 1.0329, 'grad_norm': 0.770372211933136, 'learning_rate': 8.5e-05, 'epoch': 0.03796337650736936}
{'loss': 0.9924, 'grad_norm': 0.6790789365768433, 'learning_rate': 8.6e-05, 'epoch': 0.03841000446627959}
{'loss': 1.0073, 'grad_norm': 0.670750081539154, 'learning_rate': 8.7e-05, 'epoch': 0.038856632425189816}
{'loss': 0.9293, 'grad_norm': 0.6704035997390747, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.03930326038410004}
