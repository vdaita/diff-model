[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
  0%|                                                                                                           | 0/308 [00:00<?, ?it/s]/home/vijay/.local/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
[2024-06-27 13:17:00,588] [INFO] [axolotl.callbacks.on_train_begin:770] [PID:1812524] [RANK:0] The Axolotl config has been saved to the WandB run under files.
[2024-06-27 13:17:00,591] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:1812524] [RANK:0] packing_efficiency_estimate: 0.93 total_num_tokens per device: 1197512
[2024-06-27 13:17:00,593] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:1812524] [RANK:0] packing_efficiency_estimate: 0.93 total_num_tokens per device: 1197512
  0%|▎                                                                                                | 1/308 [00:49<4:12:08, 49.28s/it]
{'loss': 0.847, 'grad_norm': 1.0460914373397827, 'learning_rate': 2e-05, 'epoch': 0.01}






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:37<00:04,  4.03s/it]


100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:41<00:00,  4.07s/it]

  1%|▌                                                                                              | 2/308 [05:27<15:37:01, 183.73s/it]
[2024-06-27 13:22:27,712] [INFO] [axolotl.callbacks.on_step_end:125] [PID:1812524] [RANK:0] GPU memory usage while training: 13.132GB (+6.069GB cache)
{'loss': 0.8866, 'grad_norm': 1.2262104749679565, 'learning_rate': 4e-05, 'epoch': 0.03}

  1%|▉                                                                                              | 3/308 [06:19<10:29:19, 123.80s/it]

  1%|█▎                                                                                               | 4/308 [07:12<8:04:38, 95.65s/it]

  2%|█▌                                                                                               | 5/308 [08:04<6:44:00, 80.00s/it]

  2%|█▉                                                                                               | 6/308 [08:56<5:55:07, 70.56s/it]

  2%|██▏                                                                                              | 7/308 [09:48<5:23:32, 64.49s/it]

  3%|██▌                                                                                              | 8/308 [10:40<5:02:45, 60.55s/it]

  3%|██▊                                                                                              | 9/308 [11:32<4:48:22, 57.87s/it]

  3%|███                                                                                             | 10/308 [12:24<4:38:44, 56.12s/it]

  4%|███▍                                                                                            | 11/308 [13:16<4:31:39, 54.88s/it]

  4%|███▋                                                                                            | 12/308 [14:09<4:26:52, 54.10s/it]

  4%|████                                                                                            | 13/308 [15:01<4:23:00, 53.49s/it]

  5%|████▎                                                                                           | 14/308 [15:53<4:19:41, 53.00s/it]

  5%|████▋                                                                                           | 15/308 [16:45<4:17:20, 52.70s/it]

  5%|████▉                                                                                           | 16/308 [17:37<4:15:27, 52.49s/it]

  6%|█████▎                                                                                          | 17/308 [18:29<4:14:00, 52.37s/it]

  6%|█████▌                                                                                          | 18/308 [19:21<4:12:51, 52.31s/it]

  6%|█████▉                                                                                          | 19/308 [20:14<4:12:23, 52.40s/it]
  6%|██████▏                                                                                         | 20/308 [21:06<4:11:37, 52.42s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:41<00:04,  4.04s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:45<00:00,  4.07s/it]


  7%|██████▍                                                                                        | 21/308 [25:48<9:39:59, 121.25s/it]
{'loss': 0.3418, 'grad_norm': 0.2357635349035263, 'learning_rate': 0.00019932836109684286, 'epoch': 0.27}

  7%|██████▊                                                                                        | 22/308 [26:40<7:59:48, 100.66s/it]

  7%|███████▏                                                                                        | 23/308 [27:33<6:49:32, 86.22s/it]

  8%|███████▍                                                                                        | 24/308 [28:25<6:00:03, 76.07s/it]

  8%|███████▊                                                                                        | 25/308 [29:18<5:25:02, 68.91s/it]

  8%|████████                                                                                        | 26/308 [30:10<5:00:25, 63.92s/it]

  9%|████████▍                                                                                       | 27/308 [31:02<4:43:10, 60.47s/it]

  9%|████████▋                                                                                       | 28/308 [31:55<4:30:57, 58.06s/it]

  9%|█████████                                                                                       | 29/308 [32:47<4:21:36, 56.26s/it]

 10%|█████████▎                                                                                      | 30/308 [33:39<4:15:34, 55.16s/it]

 10%|█████████▋                                                                                      | 31/308 [34:32<4:10:52, 54.34s/it]

 10%|█████████▉                                                                                      | 32/308 [35:24<4:07:21, 53.78s/it]


 11%|██████████▌                                                                                     | 34/308 [37:08<4:01:41, 52.93s/it]
{'loss': 0.2889, 'grad_norm': 0.20622049272060394, 'learning_rate': 0.00019681623029976588, 'epoch': 0.44}

 11%|██████████▉                                                                                     | 35/308 [38:00<3:59:28, 52.63s/it]

 12%|███████████▏                                                                                    | 36/308 [38:53<3:58:11, 52.54s/it]

 12%|███████████▌                                                                                    | 37/308 [39:45<3:56:51, 52.44s/it]

 12%|███████████▊                                                                                    | 38/308 [40:38<3:56:16, 52.51s/it]

 13%|████████████▏                                                                                   | 39/308 [41:30<3:55:31, 52.53s/it]

 13%|████████████▍                                                                                   | 40/308 [42:23<3:54:35, 52.52s/it]























































100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:45<00:00,  4.12s/it]
[2024-06-27 14:03:10,293] [INFO] [accelerate.accelerator.log:61] [PID:1812524] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.

{'eval_loss': 0.2500631511211395, 'eval_runtime': 229.3534, 'eval_samples_per_second': 0.981, 'eval_steps_per_second': 0.249, 'epoch': 0.52}

 13%|████████████▋                                                                                  | 41/308 [47:05<8:59:53, 121.32s/it]


 14%|█████████████▍                                                                                  | 43/308 [48:50<6:21:05, 86.28s/it]
{'loss': 0.2779, 'grad_norm': 0.19209611415863037, 'learning_rate': 0.000194009260539328, 'epoch': 0.55}

 14%|█████████████▋                                                                                  | 44/308 [49:43<5:35:36, 76.27s/it]

 15%|██████████████                                                                                  | 45/308 [50:35<5:03:01, 69.13s/it]

 15%|██████████████▎                                                                                 | 46/308 [51:28<4:40:05, 64.14s/it]


 16%|██████████████▉                                                                                 | 48/308 [53:12<4:11:23, 58.01s/it]

 16%|███████████████▎                                                                                | 49/308 [54:04<4:02:49, 56.25s/it]
{'loss': 0.3245, 'grad_norm': 0.19294080138206482, 'learning_rate': 0.00019166626023425662, 'epoch': 0.63}

 16%|███████████████▌                                                                                | 50/308 [54:56<3:56:49, 55.08s/it]

 17%|███████████████▉                                                                                | 51/308 [55:49<3:52:37, 54.31s/it]


 17%|████████████████▌                                                                               | 53/308 [57:34<3:47:07, 53.44s/it]
{'loss': 0.295, 'grad_norm': 0.16531433165073395, 'learning_rate': 0.00018989993441398726, 'epoch': 0.68}

 18%|████████████████▊                                                                               | 54/308 [58:27<3:45:16, 53.21s/it]

 18%|█████████████████▏                                                                              | 55/308 [59:20<3:43:46, 53.07s/it]

 18%|█████████████████                                                                             | 56/308 [1:00:12<3:42:09, 52.89s/it]

 19%|█████████████████▍                                                                            | 57/308 [1:01:04<3:40:36, 52.73s/it]

 19%|█████████████████▋                                                                            | 58/308 [1:01:57<3:39:30, 52.68s/it]

 19%|██████████████████                                                                            | 59/308 [1:02:50<3:39:05, 52.79s/it]

 19%|██████████████████▎                                                                           | 60/308 [1:03:43<3:38:39, 52.90s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:42<00:04,  4.07s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:46<00:00,  4.11s/it]

{'eval_loss': 0.2438933104276657, 'eval_runtime': 230.7226, 'eval_samples_per_second': 0.975, 'eval_steps_per_second': 0.247, 'epoch': 0.77}


 20%|██████████████████▋                                                                          | 62/308 [1:09:19<6:55:04, 101.24s/it]
{'loss': 0.2791, 'grad_norm': 0.17906256020069122, 'learning_rate': 0.00018534653450809197, 'epoch': 0.8}


 21%|███████████████████▌                                                                          | 64/308 [1:11:05<5:11:07, 76.51s/it]

 21%|███████████████████▊                                                                          | 65/308 [1:11:57<4:40:38, 69.29s/it]
{'loss': 0.2006, 'grad_norm': 0.15030933916568756, 'learning_rate': 0.00018365590083745085, 'epoch': 0.84}

 21%|████████████████████▏                                                                         | 66/308 [1:12:50<4:19:16, 64.28s/it]


 22%|████████████████████▊                                                                         | 68/308 [1:14:35<3:53:20, 58.34s/it]
{'loss': 0.271, 'grad_norm': 0.1824735850095749, 'learning_rate': 0.00018188159710183594, 'epoch': 0.88}

 22%|█████████████████████                                                                         | 69/308 [1:15:28<3:45:30, 56.61s/it]

 23%|█████████████████████▎                                                                        | 70/308 [1:16:20<3:40:03, 55.48s/it]

 23%|█████████████████████▋                                                                        | 71/308 [1:17:13<3:35:34, 54.57s/it]

 23%|█████████████████████▉                                                                        | 72/308 [1:18:05<3:32:07, 53.93s/it]

 24%|██████████████████████▎                                                                       | 73/308 [1:18:58<3:29:31, 53.49s/it]

 24%|██████████████████████▌                                                                       | 74/308 [1:19:50<3:27:34, 53.23s/it]

 24%|██████████████████████▉                                                                       | 75/308 [1:20:43<3:26:03, 53.06s/it]

 25%|███████████████████████▏                                                                      | 76/308 [1:21:36<3:24:45, 52.95s/it]
 25%|███████████████████████▌                                                                      | 77/308 [1:22:29<3:23:42, 52.91s/it]/home/vijay/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/vijay/.local/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 0.2386, 'grad_norm': 0.17433463037014008, 'learning_rate': 0.0001753863623146066, 'epoch': 1.01}
 25%|███████████████████████▊                                                                      | 78/308 [1:23:23<3:24:09, 53.26s/it]

 26%|████████████████████████                                                                      | 79/308 [1:24:15<3:22:16, 53.00s/it]
[2024-06-27 14:41:20,667] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:1812524] [RANK:0] packing_efficiency_estimate: 0.93 total_num_tokens per device: 1197512
[2024-06-27 14:41:20,669] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:1812524] [RANK:0] packing_efficiency_estimate: 0.93 total_num_tokens per device: 1197512

 26%|████████████████████████▍                                                                     | 80/308 [1:25:07<3:20:29, 52.76s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:42<00:04,  4.11s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:46<00:00,  4.14s/it]

{'eval_loss': 0.23935995995998383, 'eval_runtime': 230.9154, 'eval_samples_per_second': 0.974, 'eval_steps_per_second': 0.247, 'epoch': 1.01}

 26%|████████████████████████▍                                                                    | 81/308 [1:29:51<7:42:15, 122.18s/it]

 27%|████████████████████████▊                                                                    | 82/308 [1:30:44<6:21:55, 101.40s/it]

 27%|█████████████████████████▎                                                                    | 83/308 [1:31:37<5:25:42, 86.85s/it]

 27%|█████████████████████████▋                                                                    | 84/308 [1:32:30<4:46:26, 76.73s/it]

 28%|█████████████████████████▉                                                                    | 85/308 [1:33:24<4:18:55, 69.67s/it]

 28%|██████████████████████████▏                                                                   | 86/308 [1:34:17<3:59:20, 64.69s/it]

 28%|██████████████████████████▌                                                                   | 87/308 [1:35:10<3:45:13, 61.15s/it]

 29%|██████████████████████████▊                                                                   | 88/308 [1:36:02<3:34:56, 58.62s/it]

 29%|███████████████████████████▏                                                                  | 89/308 [1:36:55<3:27:54, 56.96s/it]

 29%|███████████████████████████▍                                                                  | 90/308 [1:37:48<3:22:34, 55.75s/it]

 30%|███████████████████████████▊                                                                  | 91/308 [1:38:41<3:18:34, 54.91s/it]

 30%|████████████████████████████                                                                  | 92/308 [1:39:34<3:15:27, 54.30s/it]

 30%|████████████████████████████▍                                                                 | 93/308 [1:40:27<3:12:45, 53.79s/it]

 31%|████████████████████████████▋                                                                 | 94/308 [1:41:20<3:10:51, 53.51s/it]

 31%|████████████████████████████▉                                                                 | 95/308 [1:42:12<3:09:18, 53.32s/it]

 31%|█████████████████████████████▎                                                                | 96/308 [1:43:05<3:07:39, 53.11s/it]

 31%|█████████████████████████████▌                                                                | 97/308 [1:43:58<3:06:32, 53.04s/it]

 32%|█████████████████████████████▉                                                                | 98/308 [1:44:51<3:05:15, 52.93s/it]

 32%|██████████████████████████████▏                                                               | 99/308 [1:45:43<3:04:04, 52.84s/it]
 32%|██████████████████████████████▏                                                              | 100/308 [1:46:36<3:02:51, 52.75s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:43<00:04,  4.08s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:47<00:00,  4.13s/it]

{'eval_loss': 0.23988665640354156, 'eval_runtime': 232.1879, 'eval_samples_per_second': 0.969, 'eval_steps_per_second': 0.245, 'epoch': 1.27}

 33%|██████████████████████████████▏                                                             | 101/308 [1:51:21<7:02:15, 122.39s/it]

 33%|██████████████████████████████▍                                                             | 102/308 [1:52:13<5:48:21, 101.46s/it]

 33%|███████████████████████████████                                                              | 103/308 [1:53:06<4:56:54, 86.90s/it]

 34%|███████████████████████████████▍                                                             | 104/308 [1:53:59<4:20:47, 76.70s/it]

 34%|███████████████████████████████▋                                                             | 105/308 [1:54:52<3:55:32, 69.62s/it]

 34%|████████████████████████████████                                                             | 106/308 [1:55:45<3:37:16, 64.54s/it]

 35%|████████████████████████████████▎                                                            | 107/308 [1:56:38<3:24:25, 61.02s/it]

 35%|████████████████████████████████▌                                                            | 108/308 [1:57:31<3:15:32, 58.66s/it]

 35%|████████████████████████████████▉                                                            | 109/308 [1:58:24<3:08:42, 56.89s/it]

 36%|█████████████████████████████████▏                                                           | 110/308 [1:59:17<3:03:45, 55.69s/it]

 36%|█████████████████████████████████▌                                                           | 111/308 [2:00:09<2:59:55, 54.80s/it]


 37%|██████████████████████████████████                                                           | 113/308 [2:01:54<2:54:30, 53.70s/it]
{'loss': 0.2033, 'grad_norm': 0.1822996735572815, 'learning_rate': 0.0001466158668674112, 'epoch': 1.44}

 37%|██████████████████████████████████▍                                                          | 114/308 [2:02:47<2:52:37, 53.39s/it]

 37%|██████████████████████████████████▋                                                          | 115/308 [2:03:40<2:51:25, 53.29s/it]

 38%|███████████████████████████████████                                                          | 116/308 [2:04:33<2:49:51, 53.08s/it]

 38%|███████████████████████████████████▎                                                         | 117/308 [2:05:26<2:48:44, 53.01s/it]

 38%|███████████████████████████████████▋                                                         | 118/308 [2:06:18<2:47:43, 52.97s/it]

 39%|███████████████████████████████████▉                                                         | 119/308 [2:07:11<2:46:25, 52.83s/it]
 39%|████████████████████████████████████▏                                                        | 120/308 [2:08:03<2:45:08, 52.70s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:41<00:04,  4.08s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:46<00:00,  4.12s/it]

{'eval_loss': 0.24158456921577454, 'eval_runtime': 230.171, 'eval_samples_per_second': 0.978, 'eval_steps_per_second': 0.248, 'epoch': 1.53}

 39%|████████████████████████████████████▏                                                       | 121/308 [2:12:46<6:19:38, 121.81s/it]

 40%|████████████████████████████████████▍                                                       | 122/308 [2:13:39<5:13:18, 101.07s/it]

 40%|█████████████████████████████████████▏                                                       | 123/308 [2:14:32<4:26:43, 86.51s/it]

 40%|█████████████████████████████████████▍                                                       | 124/308 [2:15:24<3:53:54, 76.27s/it]

 41%|█████████████████████████████████████▋                                                       | 125/308 [2:16:17<3:30:53, 69.14s/it]

 41%|██████████████████████████████████████                                                       | 126/308 [2:17:09<3:14:15, 64.04s/it]

 41%|██████████████████████████████████████▎                                                      | 127/308 [2:18:01<3:02:42, 60.57s/it]

 42%|██████████████████████████████████████▋                                                      | 128/308 [2:18:54<2:54:33, 58.19s/it]

 42%|██████████████████████████████████████▉                                                      | 129/308 [2:19:46<2:48:32, 56.49s/it]

 42%|███████████████████████████████████████▎                                                     | 130/308 [2:20:39<2:44:01, 55.29s/it]


 43%|███████████████████████████████████████▊                                                     | 132/308 [2:22:24<2:37:56, 53.84s/it]

 43%|████████████████████████████████████████▏                                                    | 133/308 [2:23:16<2:35:32, 53.33s/it]
{'loss': 0.2934, 'grad_norm': 0.21163736283779144, 'learning_rate': 0.00012706793812973941, 'epoch': 1.69}

 44%|████████████████████████████████████████▍                                                    | 134/308 [2:24:08<2:33:48, 53.03s/it]

 44%|████████████████████████████████████████▊                                                    | 135/308 [2:25:01<2:32:27, 52.88s/it]

 44%|█████████████████████████████████████████                                                    | 136/308 [2:25:53<2:31:08, 52.72s/it]

 44%|█████████████████████████████████████████▎                                                   | 137/308 [2:26:45<2:29:49, 52.57s/it]

 45%|█████████████████████████████████████████▋                                                   | 138/308 [2:27:38<2:28:48, 52.52s/it]

 45%|█████████████████████████████████████████▉                                                   | 139/308 [2:28:30<2:27:57, 52.53s/it]

 45%|██████████████████████████████████████████▎                                                  | 140/308 [2:29:23<2:27:12, 52.57s/it]























































100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:46<00:00,  4.12s/it]
[2024-06-27 15:50:11,520] [INFO] [accelerate.accelerator.log:61] [PID:1812524] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.

{'eval_loss': 0.239952951669693, 'eval_runtime': 230.2751, 'eval_samples_per_second': 0.977, 'eval_steps_per_second': 0.248, 'epoch': 1.78}


 46%|██████████████████████████████████████████▍                                                 | 142/308 [2:34:59<4:39:26, 101.00s/it]
{'loss': 0.2464, 'grad_norm': 0.19886913895606995, 'learning_rate': 0.0001178260519879937, 'epoch': 1.81}

 46%|███████████████████████████████████████████▏                                                 | 143/308 [2:35:51<3:57:47, 86.47s/it]

 47%|███████████████████████████████████████████▍                                                 | 144/308 [2:36:44<3:28:37, 76.32s/it]

 47%|███████████████████████████████████████████▊                                                 | 145/308 [2:37:36<3:07:54, 69.17s/it]

 47%|████████████████████████████████████████████                                                 | 146/308 [2:38:29<2:53:03, 64.09s/it]

 48%|████████████████████████████████████████████▍                                                | 147/308 [2:39:21<2:42:37, 60.60s/it]

 48%|████████████████████████████████████████████▋                                                | 148/308 [2:40:14<2:35:05, 58.16s/it]

 48%|████████████████████████████████████████████▉                                                | 149/308 [2:41:06<2:29:19, 56.35s/it]

 49%|█████████████████████████████████████████████▎                                               | 150/308 [2:41:58<2:25:04, 55.09s/it]

 49%|█████████████████████████████████████████████▌                                               | 151/308 [2:42:50<2:21:36, 54.12s/it]

 49%|█████████████████████████████████████████████▉                                               | 152/308 [2:43:42<2:19:01, 53.47s/it]

 50%|██████████████████████████████████████████████▏                                              | 153/308 [2:44:34<2:17:00, 53.04s/it]
 50%|██████████████████████████████████████████████▌                                              | 154/308 [2:45:26<2:15:24, 52.75s/it]/home/vijay/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/vijay/.local/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 50%|██████████████████████████████████████████████▊                                              | 155/308 [2:46:19<2:15:14, 53.04s/it]
{'loss': 0.2349, 'grad_norm': 0.18630804121494293, 'learning_rate': 0.00010421565323340971, 'epoch': 1.98}

 51%|███████████████████████████████████████████████                                              | 156/308 [2:47:12<2:13:50, 52.83s/it]


 51%|███████████████████████████████████████████████▋                                             | 158/308 [2:48:56<2:10:53, 52.36s/it]
{'loss': 0.2544, 'grad_norm': 0.21523377299308777, 'learning_rate': 0.00010105420619515798, 'epoch': 2.02}
[2024-06-27 16:06:05,677] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:1812524] [RANK:0] packing_efficiency_estimate: 0.93 total_num_tokens per device: 1197512
[2024-06-27 16:06:05,679] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:1812524] [RANK:0] packing_efficiency_estimate: 0.93 total_num_tokens per device: 1197512

 52%|████████████████████████████████████████████████                                             | 159/308 [2:49:48<2:09:54, 52.31s/it]
 52%|████████████████████████████████████████████████▎                                            | 160/308 [2:50:40<2:08:52, 52.25s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:41<00:04,  4.06s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:45<00:00,  4.09s/it]

{'eval_loss': 0.23877990245819092, 'eval_runtime': 229.4751, 'eval_samples_per_second': 0.98, 'eval_steps_per_second': 0.248, 'epoch': 2.02}


 53%|████████████████████████████████████████████████▍                                           | 162/308 [2:56:14<4:04:24, 100.45s/it]
{'loss': 0.2024, 'grad_norm': 0.17123450338840485, 'learning_rate': 9.683785005164411e-05, 'epoch': 2.05}


 53%|█████████████████████████████████████████████████▌                                           | 164/308 [2:57:58<3:01:58, 75.82s/it]
{'loss': 0.1555, 'grad_norm': 0.1889830231666565, 'learning_rate': 9.473131200147205e-05, 'epoch': 2.07}

 54%|█████████████████████████████████████████████████▊                                           | 165/308 [2:58:51<2:43:59, 68.81s/it]

 54%|██████████████████████████████████████████████████                                           | 166/308 [2:59:43<2:31:17, 63.93s/it]

 54%|██████████████████████████████████████████████████▍                                          | 167/308 [3:00:36<2:22:13, 60.52s/it]

 55%|██████████████████████████████████████████████████▋                                          | 168/308 [3:01:28<2:15:36, 58.12s/it]

 55%|███████████████████████████████████████████████████                                          | 169/308 [3:02:21<2:10:49, 56.47s/it]


 56%|███████████████████████████████████████████████████▋                                         | 171/308 [3:04:07<2:04:43, 54.63s/it]
{'loss': 0.1909, 'grad_norm': 0.23838435113430023, 'learning_rate': 8.738300808386935e-05, 'epoch': 2.16}

 56%|███████████████████████████████████████████████████▉                                         | 172/308 [3:04:59<2:02:24, 54.00s/it]

 56%|████████████████████████████████████████████████████▏                                        | 173/308 [3:05:52<2:00:36, 53.60s/it]

 56%|████████████████████████████████████████████████████▌                                        | 174/308 [3:06:44<1:58:56, 53.26s/it]

 57%|████████████████████████████████████████████████████▊                                        | 175/308 [3:07:37<1:57:35, 53.05s/it]

 57%|█████████████████████████████████████████████████████▏                                       | 176/308 [3:08:29<1:56:26, 52.93s/it]


 58%|█████████████████████████████████████████████████████▋                                       | 178/308 [3:10:15<1:54:21, 52.78s/it]
{'loss': 0.1407, 'grad_norm': 0.22832471132278442, 'learning_rate': 8.010338285937006e-05, 'epoch': 2.25}

 58%|██████████████████████████████████████████████████████                                       | 179/308 [3:11:07<1:53:26, 52.77s/it]

 58%|██████████████████████████████████████████████████████▎                                      | 180/308 [3:12:00<1:52:26, 52.70s/it]

















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:43<00:04,  4.09s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:47<00:00,  4.12s/it]

{'eval_loss': 0.2557351589202881, 'eval_runtime': 231.6853, 'eval_samples_per_second': 0.971, 'eval_steps_per_second': 0.246, 'epoch': 2.28}

 59%|██████████████████████████████████████████████████████                                      | 181/308 [3:16:44<4:18:37, 122.18s/it]

 59%|██████████████████████████████████████████████████████▎                                     | 182/308 [3:17:37<3:32:40, 101.28s/it]

 59%|███████████████████████████████████████████████████████▎                                     | 183/308 [3:18:30<3:00:42, 86.74s/it]

 60%|███████████████████████████████████████████████████████▌                                     | 184/308 [3:19:22<2:38:08, 76.52s/it]


 60%|████████████████████████████████████████████████████████▏                                    | 186/308 [3:21:08<2:10:53, 64.37s/it]
{'loss': 0.143, 'grad_norm': 0.19291909039020538, 'learning_rate': 7.191871380165538e-05, 'epoch': 2.35}

 61%|████████████████████████████████████████████████████████▍                                    | 187/308 [3:22:00<2:02:46, 60.88s/it]

 61%|████████████████████████████████████████████████████████▊                                    | 188/308 [3:22:53<1:56:38, 58.32s/it]


 62%|█████████████████████████████████████████████████████████▎                                   | 190/308 [3:24:38<1:48:49, 55.33s/it]
{'loss': 0.1479, 'grad_norm': 0.24084055423736572, 'learning_rate': 6.789765149027039e-05, 'epoch': 2.41}

 62%|█████████████████████████████████████████████████████████▋                                   | 191/308 [3:25:30<1:46:12, 54.47s/it]

 62%|█████████████████████████████████████████████████████████▉                                   | 192/308 [3:26:22<1:44:04, 53.83s/it]

 63%|██████████████████████████████████████████████████████████▎                                  | 193/308 [3:27:15<1:42:28, 53.47s/it]


 63%|██████████████████████████████████████████████████████████▉                                  | 195/308 [3:29:00<1:39:45, 52.97s/it]
{'loss': 0.1469, 'grad_norm': 0.23522444069385529, 'learning_rate': 6.295241618302156e-05, 'epoch': 2.47}

 64%|███████████████████████████████████████████████████████████▏                                 | 196/308 [3:29:53<1:38:36, 52.82s/it]

 64%|███████████████████████████████████████████████████████████▍                                 | 197/308 [3:30:45<1:37:29, 52.70s/it]

 64%|███████████████████████████████████████████████████████████▊                                 | 198/308 [3:31:37<1:36:22, 52.57s/it]

 65%|████████████████████████████████████████████████████████████                                 | 199/308 [3:32:30<1:35:23, 52.51s/it]

 65%|████████████████████████████████████████████████████████████▍                                | 200/308 [3:33:22<1:34:24, 52.45s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:42<00:04,  4.07s/it]


100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:46<00:00,  4.11s/it]

 65%|████████████████████████████████████████████████████████████                                | 201/308 [3:38:05<3:36:46, 121.55s/it]

 66%|████████████████████████████████████████████████████████████▎                               | 202/308 [3:38:57<2:57:59, 100.75s/it]
{'loss': 0.1879, 'grad_norm': 0.23784585297107697, 'learning_rate': 5.620500265600206e-05, 'epoch': 2.56}

 66%|█████████████████████████████████████████████████████████████▎                               | 203/308 [3:39:49<2:30:55, 86.25s/it]

 66%|█████████████████████████████████████████████████████████████▌                               | 204/308 [3:40:42<2:11:46, 76.03s/it]

 67%|█████████████████████████████████████████████████████████████▉                               | 205/308 [3:41:34<1:58:12, 68.86s/it]

 67%|██████████████████████████████████████████████████████████████▏                              | 206/308 [3:42:26<1:48:28, 63.81s/it]

 67%|██████████████████████████████████████████████████████████████▌                              | 207/308 [3:43:18<1:41:36, 60.36s/it]

 68%|██████████████████████████████████████████████████████████████▊                              | 208/308 [3:44:10<1:36:39, 58.00s/it]

 68%|███████████████████████████████████████████████████████████████                              | 209/308 [3:45:03<1:32:57, 56.34s/it]


 69%|███████████████████████████████████████████████████████████████▋                             | 211/308 [3:46:47<1:27:37, 54.21s/it]

 69%|████████████████████████████████████████████████████████████████                             | 212/308 [3:47:40<1:25:48, 53.63s/it]
{'loss': 0.1431, 'grad_norm': 0.2618773579597473, 'learning_rate': 4.698820760623064e-05, 'epoch': 2.69}

 69%|████████████████████████████████████████████████████████████████▎                            | 213/308 [3:48:32<1:24:17, 53.24s/it]

 69%|████████████████████████████████████████████████████████████████▌                            | 214/308 [3:49:24<1:23:01, 52.99s/it]


 70%|█████████████████████████████████████████████████████████████████▏                           | 216/308 [3:51:09<1:20:57, 52.79s/it]
{'loss': 0.1446, 'grad_norm': 0.22744332253932953, 'learning_rate': 4.346078087600412e-05, 'epoch': 2.74}

 70%|█████████████████████████████████████████████████████████████████▌                           | 217/308 [3:52:02<1:19:59, 52.74s/it]

 71%|█████████████████████████████████████████████████████████████████▊                           | 218/308 [3:52:55<1:18:58, 52.66s/it]

 71%|██████████████████████████████████████████████████████████████████▏                          | 219/308 [3:53:47<1:18:01, 52.60s/it]

 71%|██████████████████████████████████████████████████████████████████▍                          | 220/308 [3:54:40<1:17:06, 52.58s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:42<00:04,  4.06s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:46<00:00,  4.10s/it]

{'eval_loss': 0.2626844346523285, 'eval_runtime': 230.9971, 'eval_samples_per_second': 0.974, 'eval_steps_per_second': 0.247, 'epoch': 2.79}

 72%|██████████████████████████████████████████████████████████████████                          | 221/308 [3:59:23<2:56:42, 121.87s/it]


 72%|███████████████████████████████████████████████████████████████████▎                         | 223/308 [4:01:08<2:02:38, 86.57s/it]
{'loss': 0.1998, 'grad_norm': 0.2702022194862366, 'learning_rate': 3.7533343872709294e-05, 'epoch': 2.83}

 73%|███████████████████████████████████████████████████████████████████▋                         | 224/308 [4:02:01<1:46:53, 76.35s/it]

 73%|███████████████████████████████████████████████████████████████████▉                         | 225/308 [4:02:53<1:35:35, 69.10s/it]

 73%|████████████████████████████████████████████████████████████████████▏                        | 226/308 [4:03:45<1:27:28, 64.01s/it]

 74%|████████████████████████████████████████████████████████████████████▌                        | 227/308 [4:04:37<1:21:27, 60.34s/it]

 74%|████████████████████████████████████████████████████████████████████▊                        | 228/308 [4:05:29<1:17:11, 57.90s/it]

 74%|█████████████████████████████████████████████████████████████████████▏                       | 229/308 [4:06:21<1:13:57, 56.17s/it]

 75%|█████████████████████████████████████████████████████████████████████▍                       | 230/308 [4:07:13<1:11:21, 54.90s/it]
 75%|█████████████████████████████████████████████████████████████████████▊                       | 231/308 [4:08:05<1:09:21, 54.04s/it]/home/vijay/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/vijay/.local/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
 75%|██████████████████████████████████████████████████████████████████████                       | 232/308 [4:08:59<1:08:10, 53.83s/it]
{'loss': 0.1438, 'grad_norm': 0.24292853474617004, 'learning_rate': 3.041629139962283e-05, 'epoch': 2.95}

 76%|██████████████████████████████████████████████████████████████████████▎                      | 233/308 [4:09:50<1:06:27, 53.17s/it]

 76%|██████████████████████████████████████████████████████████████████████▋                      | 234/308 [4:10:42<1:05:08, 52.82s/it]

 76%|██████████████████████████████████████████████████████████████████████▉                      | 235/308 [4:11:34<1:03:58, 52.58s/it]


 77%|███████████████████████████████████████████████████████████████████████▌                     | 237/308 [4:13:19<1:02:04, 52.46s/it]
{'loss': 0.1635, 'grad_norm': 0.2471533715724945, 'learning_rate': 2.672896755720654e-05, 'epoch': 3.01}
[2024-06-27 17:30:33,442] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:1812524] [RANK:0] packing_efficiency_estimate: 0.93 total_num_tokens per device: 1197512
[2024-06-27 17:30:33,444] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:1812524] [RANK:0] packing_efficiency_estimate: 0.93 total_num_tokens per device: 1197512

 77%|███████████████████████████████████████████████████████████████████████▊                     | 238/308 [4:14:11<1:01:13, 52.47s/it]

 78%|████████████████████████████████████████████████████████████████████████▏                    | 239/308 [4:15:04<1:00:14, 52.38s/it]
 78%|██████████████████████████████████████████████████████████████████████████                     | 240/308 [4:15:56<59:18, 52.34s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:40<00:04,  4.05s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:44<00:00,  4.09s/it]

{'eval_loss': 0.262809157371521, 'eval_runtime': 229.0954, 'eval_samples_per_second': 0.982, 'eval_steps_per_second': 0.249, 'epoch': 3.03}


 79%|████████████████████████████████████████████████████████████████████████▎                   | 242/308 [4:21:29<1:50:27, 100.41s/it]
{'loss': 0.1146, 'grad_norm': 0.20244118571281433, 'learning_rate': 2.324517865697501e-05, 'epoch': 3.05}


 79%|█████████████████████████████████████████████████████████████████████████▋                   | 244/308 [4:23:14<1:20:49, 75.78s/it]

 80%|█████████████████████████████████████████████████████████████████████████▉                   | 245/308 [4:24:06<1:12:07, 68.69s/it]
{'loss': 0.1533, 'grad_norm': 0.22769063711166382, 'learning_rate': 2.125665222227675e-05, 'epoch': 3.09}


 80%|██████████████████████████████████████████████████████████████████████████▌                  | 247/308 [4:25:50<1:01:12, 60.21s/it]

 81%|████████████████████████████████████████████████████████████████████████████▍                  | 248/308 [4:26:42<57:44, 57.74s/it]
{'loss': 0.0934, 'grad_norm': 0.22442200779914856, 'learning_rate': 1.9346882467727325e-05, 'epoch': 3.13}


 81%|█████████████████████████████████████████████████████████████████████████████                  | 250/308 [4:28:26<53:01, 54.85s/it]

 81%|█████████████████████████████████████████████████████████████████████████████▍                 | 251/308 [4:29:18<51:22, 54.08s/it]
{'loss': 0.1361, 'grad_norm': 0.276484876871109, 'learning_rate': 1.7517779486432495e-05, 'epoch': 3.17}

 82%|█████████████████████████████████████████████████████████████████████████████▋                 | 252/308 [4:30:11<50:02, 53.61s/it]

 82%|██████████████████████████████████████████████████████████████████████████████                 | 253/308 [4:31:03<48:45, 53.19s/it]

 82%|██████████████████████████████████████████████████████████████████████████████▎                | 254/308 [4:31:55<47:35, 52.87s/it]

 83%|██████████████████████████████████████████████████████████████████████████████▋                | 255/308 [4:32:48<46:38, 52.80s/it]


 83%|███████████████████████████████████████████████████████████████████████████████▎               | 257/308 [4:34:32<44:43, 52.62s/it]
{'loss': 0.1067, 'grad_norm': 0.2733009457588196, 'learning_rate': 1.4108808984151023e-05, 'epoch': 3.25}

 84%|███████████████████████████████████████████████████████████████████████████████▌               | 258/308 [4:35:25<43:47, 52.55s/it]

 84%|███████████████████████████████████████████████████████████████████████████████▉               | 259/308 [4:36:17<42:53, 52.53s/it]

 84%|████████████████████████████████████████████████████████████████████████████████▏              | 260/308 [4:37:10<42:00, 52.52s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:42<00:04,  4.06s/it]

100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:46<00:00,  4.09s/it]


 85%|█████████████████████████████████████████████████████████████████████████████▉              | 261/308 [4:41:53<1:35:17, 121.64s/it]
{'loss': 0.0947, 'grad_norm': 0.2458527833223343, 'learning_rate': 1.2026230208951306e-05, 'epoch': 3.3}

 85%|██████████████████████████████████████████████████████████████████████████████▎             | 262/308 [4:42:45<1:17:21, 100.91s/it]

 85%|███████████████████████████████████████████████████████████████████████████████▍             | 263/308 [4:43:38<1:04:49, 86.44s/it]


 86%|█████████████████████████████████████████████████████████████████████████████████▋             | 265/308 [4:45:23<49:30, 69.09s/it]
{'loss': 0.1083, 'grad_norm': 0.25417089462280273, 'learning_rate': 1.010006558601274e-05, 'epoch': 3.35}

 86%|██████████████████████████████████████████████████████████████████████████████████             | 266/308 [4:46:15<44:53, 64.14s/it]

 87%|██████████████████████████████████████████████████████████████████████████████████▎            | 267/308 [4:47:08<41:23, 60.58s/it]

 87%|██████████████████████████████████████████████████████████████████████████████████▋            | 268/308 [4:48:00<38:43, 58.10s/it]

 87%|██████████████████████████████████████████████████████████████████████████████████▉            | 269/308 [4:48:52<36:38, 56.38s/it]

 88%|███████████████████████████████████████████████████████████████████████████████████▎           | 270/308 [4:49:44<34:52, 55.07s/it]

 88%|███████████████████████████████████████████████████████████████████████████████████▌           | 271/308 [4:50:37<33:28, 54.28s/it]

 88%|███████████████████████████████████████████████████████████████████████████████████▉           | 272/308 [4:51:29<32:10, 53.62s/it]

 89%|████████████████████████████████████████████████████████████████████████████████████▏          | 273/308 [4:52:21<31:01, 53.19s/it]

 89%|████████████████████████████████████████████████████████████████████████████████████▌          | 274/308 [4:53:13<29:56, 52.84s/it]

 89%|████████████████████████████████████████████████████████████████████████████████████▊          | 275/308 [4:54:05<28:56, 52.61s/it]

 90%|█████████████████████████████████████████████████████████████████████████████████████▏         | 276/308 [4:54:57<27:58, 52.46s/it]


 90%|█████████████████████████████████████████████████████████████████████████████████████▋         | 278/308 [4:56:42<26:13, 52.44s/it]
{'loss': 0.0936, 'grad_norm': 0.3939734101295471, 'learning_rate': 4.959714454271369e-06, 'epoch': 3.52}

 91%|██████████████████████████████████████████████████████████████████████████████████████         | 279/308 [4:57:34<25:18, 52.36s/it]

 91%|██████████████████████████████████████████████████████████████████████████████████████▎        | 280/308 [4:58:27<24:29, 52.49s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:42<00:04,  4.08s/it]


100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:46<00:00,  4.11s/it]

 91%|█████████████████████████████████████████████████████████████████████████████████████▊        | 281/308 [5:03:10<54:47, 121.74s/it]
{'loss': 0.0831, 'grad_norm': 0.2301350086927414, 'learning_rate': 4.023745825091407e-06, 'epoch': 3.56}

 92%|██████████████████████████████████████████████████████████████████████████████████████        | 282/308 [5:04:03<43:44, 100.96s/it]

 92%|███████████████████████████████████████████████████████████████████████████████████████▎       | 283/308 [5:04:55<35:58, 86.34s/it]

 92%|███████████████████████████████████████████████████████████████████████████████████████▌       | 284/308 [5:05:47<30:25, 76.07s/it]

 93%|███████████████████████████████████████████████████████████████████████████████████████▉       | 285/308 [5:06:39<26:24, 68.90s/it]

 93%|████████████████████████████████████████████████████████████████████████████████████████▏      | 286/308 [5:07:32<23:27, 63.96s/it]


 94%|████████████████████████████████████████████████████████████████████████████████████████▊      | 288/308 [5:09:17<19:20, 58.04s/it]

 94%|█████████████████████████████████████████████████████████████████████████████████████████▏     | 289/308 [5:10:09<17:50, 56.32s/it]
{'loss': 0.0903, 'grad_norm': 0.2638411521911621, 'learning_rate': 1.9993641532913833e-06, 'epoch': 3.66}

 94%|█████████████████████████████████████████████████████████████████████████████████████████▍     | 290/308 [5:11:01<16:33, 55.18s/it]

 94%|█████████████████████████████████████████████████████████████████████████████████████████▊     | 291/308 [5:11:53<15:22, 54.27s/it]

 95%|██████████████████████████████████████████████████████████████████████████████████████████     | 292/308 [5:12:46<14:18, 53.68s/it]

 95%|██████████████████████████████████████████████████████████████████████████████████████████▎    | 293/308 [5:13:38<13:16, 53.13s/it]

 95%|██████████████████████████████████████████████████████████████████████████████████████████▋    | 294/308 [5:14:30<12:20, 52.88s/it]

 96%|██████████████████████████████████████████████████████████████████████████████████████████▉    | 295/308 [5:15:22<11:26, 52.78s/it]

 96%|███████████████████████████████████████████████████████████████████████████████████████████▎   | 296/308 [5:16:15<10:30, 52.57s/it]


 97%|███████████████████████████████████████████████████████████████████████████████████████████▉   | 298/308 [5:17:59<08:44, 52.43s/it]
{'loss': 0.1142, 'grad_norm': 0.2427329272031784, 'learning_rate': 5.55181464516652e-07, 'epoch': 3.78}

 97%|████████████████████████████████████████████████████████████████████████████████████████████▏  | 299/308 [5:18:52<07:52, 52.56s/it]

 97%|████████████████████████████████████████████████████████████████████████████████████████████▌  | 300/308 [5:19:44<07:00, 52.53s/it]






















































 98%|█████████████████████████████████████████████████████████████████████████████████████████████████▏ | 55/56 [03:42<00:04,  4.06s/it]


100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [03:47<00:00,  4.09s/it]
{'eval_loss': 0.2883225083351135, 'eval_runtime': 231.2541, 'eval_samples_per_second': 0.973, 'eval_steps_per_second': 0.246, 'epoch': 3.8}

 98%|███████████████████████████████████████████████████████████████████████████████████████████▊  | 301/308 [5:24:28<14:13, 121.93s/it]


 98%|█████████████████████████████████████████████████████████████████████████████████████████████▍ | 303/308 [5:26:14<07:12, 86.56s/it]

 99%|█████████████████████████████████████████████████████████████████████████████████████████████▊ | 304/308 [5:27:06<05:05, 76.36s/it]
{'loss': 0.0652, 'grad_norm': 0.22414226830005646, 'learning_rate': 8.889817534969425e-08, 'epoch': 3.85}

 99%|██████████████████████████████████████████████████████████████████████████████████████████████ | 305/308 [5:27:59<03:27, 69.22s/it]

 99%|██████████████████████████████████████████████████████████████████████████████████████████████▍| 306/308 [5:28:51<02:08, 64.16s/it]

100%|██████████████████████████████████████████████████████████████████████████████████████████████▋| 307/308 [5:29:43<01:00, 60.61s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 308/308 [5:30:36<00:00, 58.09s/it]/home/vijay/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'train_runtime': 19838.598, 'train_samples_per_second': 0.862, 'train_steps_per_second': 0.016, 'train_loss': 0.21804703975265677, 'epoch': 3.91}
[2024-06-27 18:47:37,937] [INFO] [axolotl.train.log:61] [PID:1812524] [RANK:0] Training Completed!!! Saving pre-trained model to ./outputs/axolotl-qlora-out-line
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 308/308 [5:30:37<00:00, 64.41s/it]
/home/vijay/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(